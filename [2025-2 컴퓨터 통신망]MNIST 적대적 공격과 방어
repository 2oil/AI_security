{"cells":[{"cell_type":"markdown","source":["## 1. 기초 모델 구축"],"metadata":{"id":"ywlv6ElztbBu"}},{"cell_type":"markdown","source":["1-1. MNIST 데이터셋 불러오기"],"metadata":{"id":"O4j-akAbtsT5"}},{"cell_type":"code","source":["from tensorflow.keras.datasets import mnist\n","\n","# 데이터 불러오기\n","(x_train, y_train), (x_test, y_test) = mnist.load_data()\n","\n","# 정규화 (0~1)\n","x_train = x_train.astype(\"float32\") / 255.0\n","x_test = x_test.astype(\"float32\") / 255.0\n","\n","print(x_train.shape, y_train.shape)\n","print(x_test.shape, y_test.shape)"],"metadata":{"id":"7yjygsPJtnxe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","# 샘플 시각화\n","plt.figure(figsize=(5,5))\n","for i in range(25):\n","    plt.subplot(5,5,i+1)\n","    plt.imshow(x_train[i], cmap=\"gray\")\n","    plt.title(y_train[i])\n","    plt.axis(\"off\")\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"6qnvkHjpt0yf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["1-2. 간단한 CNN 분류 모델 설계 및 학습"],"metadata":{"id":"hLMSxj5zvSCC"}},{"cell_type":"code","source":["from tensorflow.keras import layers, models\n","\n","# CNN 분류 모델 정의\n","model = models.Sequential([\n","    layers.Conv2D(32, kernel_size=(3,3), activation='relu', input_shape=(28,28,1)),\n","    layers.Conv2D(64, kernel_size=(3,3), activation='relu'),\n","    layers.MaxPooling2D(pool_size=(2,2)),\n","    layers.Dropout(0.25),\n","    layers.Flatten(),\n","    layers.Dense(128, activation='relu'),\n","    layers.Dropout(0.5),\n","    layers.Dense(10, activation='softmax')\n","])\n","\n","# 모델 컴파일\n","model.compile(\n","    optimizer='adam',\n","    loss='sparse_categorical_crossentropy',\n","    metrics=['accuracy']\n",")\n","\n","# 모델 요약도\n","model.summary()"],"metadata":{"id":"Ko7PnKSvuNEP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# 모델 학습\n","history = model.fit(\n","    x_train, y_train,\n","    epochs=5, # epoch : 전체 데이터를 1회 학습하는 횟수\n","    batch_size=64, # 한 번에 64개 샘플씩 나눠서 학습\n","    validation_split=0.2, # 학습 데이터의 20%를 validation set으로 사용\n","    verbose=1\n",")\n","\n","# 학습 완료 후 모델 저장\n","save_path = \"/content/drive/MyDrive/mnist_cnn_tf.keras\"\n","model.save(save_path)"],"metadata":{"id":"dtC5zJ9pvmd3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","# 정확도(Accuracy) 그래프\n","plt.figure(figsize=(7,4))\n","plt.plot(history.history['accuracy'], 'o-', label='Train Accuracy')\n","plt.plot(history.history['val_accuracy'], 's-', label='Validation Accuracy')\n","plt.title('Training and Validation Accuracy')\n","plt.xlabel('Epoch')\n","plt.ylabel('Accuracy')\n","plt.legend()\n","plt.grid(True, linestyle='--', alpha=0.6)\n","plt.show()\n","\n","# 손실(Loss) 그래프\n","plt.figure(figsize=(7,4))\n","plt.plot(history.history['loss'], 'o-', label='Train Loss')\n","plt.plot(history.history['val_loss'], 's-', label='Validation Loss')\n","plt.title('Training and Validation Loss')\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.legend()\n","plt.grid(True, linestyle='--', alpha=0.6)\n","plt.show()\n"],"metadata":{"id":"tnyQRYaM4gB1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["1-3. 정상 데이터 정확도 측정"],"metadata":{"id":"SqQTyxKA1aAN"}},{"cell_type":"code","source":["# 테스트셋 평가\n","test_loss, test_acc = model.evaluate(x_test, y_test, verbose=1)\n","print(f\"\\n정상 데이터 정확도: {test_acc*100:.2f}%\")"],"metadata":{"id":"xHBfMQWhwSCO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 2. 적대적 공격 실험"],"metadata":{"id":"jRjSZ2ee4qfI"}},{"cell_type":"markdown","source":["2-1. FGSM 공격 구현"],"metadata":{"id":"82jWo3h84ubI"}},{"cell_type":"code","source":["import tensorflow as tf\n","import numpy as np\n","\n","# 적대적 공격 loss 정의\n","loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n","\n","# FGSM 공격 함수\n","def fgsm(model, images, labels, epsilon):\n","    images = tf.convert_to_tensor(images)\n","    labels = tf.convert_to_tensor(labels) # 텐서로 변환\n","    with tf.GradientTape() as tape:\n","        tape.watch(images)\n","        preds = model(images, training=False)\n","        loss = loss_object(labels, preds) # 입력값을 받았을 때 모델의 loss\n","    grad = tape.gradient(loss, images)\n","    signed_grad = tf.sign(grad) # loss가 증가하는 gradient의 방향\n","    adv = images + epsilon * signed_grad # 원본 이미지에 적대적 교란 삽입\n","    adv = tf.clip_by_value(adv, 0.0, 1.0)\n","    return adv\n","\n","# 배치 별 FGSM 공격 적용 및 정확도 계산 함수\n","def eval_fgsm(model, x, y, epsilon, batch_size=1024):\n","    loss, clean_acc = model.evaluate(x, y, batch_size=batch_size, verbose=0)\n","\n","    adv_preds = []\n","    n = x.shape[0]\n","    for i in range(0, n, batch_size):\n","        xb = x[i:i+batch_size]\n","        yb = y[i:i+batch_size]\n","        adv = fgsm(model, xb, yb, tf.constant(epsilon, dtype=tf.float32))\n","        preds = model.predict(adv, verbose=0)\n","        adv_preds.append(np.argmax(preds, axis=1))\n","    adv_preds = np.concatenate(adv_preds, axis=0)\n","    adv_acc = (adv_preds == y).mean()\n","    return float(clean_acc), float(adv_acc)"],"metadata":{"id":"AbKQeCu44Vzn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["2-2. 공격된 이미지 시각화"],"metadata":{"id":"fSco9YbKCjnc"}},{"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","\n","idx = 6\n","# 여러 eps 값 (적대적 교란의 크기)\n","epsilons = [0.05, 0.1, 0.2, 0.3]\n","\n","# 저장된 모델 불러오기\n","model = tf.keras.models.load_model(\"/content/drive/MyDrive/mnist_cnn_tf.keras\")\n","\n","# 원본 데이터\n","orig = x_test[idx:idx+1]\n","true_label = int(y_test[idx])\n","\n","# 원본 예측\n","pred_orig = int(np.argmax(model.predict(orig, verbose=0), axis=1)[0])\n","\n","# 적대적 예제 생성 및 예측\n","advs = []\n","preds_adv = []\n","for eps in epsilons:\n","    adv = fgsm(model, orig, np.array([true_label]), tf.constant(eps, dtype=tf.float32)).numpy()\n","    advs.append(adv)\n","    preds_adv.append(int(np.argmax(model.predict(adv, verbose=0), axis=1)[0]))\n","\n","# 채널 차원이 있는지 확인 (gray 이미지 처리용)\n","def get_image(arr):\n","    if arr.ndim == 4:\n","        return arr[0, :, :, 0]\n","    elif arr.ndim == 3:\n","        return arr[0, :, :]\n","    else:\n","        return arr\n","\n","# 시각화\n","n_cols = len(epsilons) + 1\n","plt.figure(figsize=(3*n_cols, 3))\n","\n","for i in range(n_cols):\n","    ax = plt.subplot(1, n_cols, i+1)\n","    if i == 0:\n","        img = orig.squeeze()\n","        title = f\"Original\\ntrue={true_label}\\npred={pred_orig}\"\n","    else:\n","        img = advs[i-1].squeeze()\n","        title = f\"Adv (ε={epsilons[i-1]})\\ntrue={true_label}\\npred={preds_adv[i-1]}\"\n","    ax.imshow(img, cmap='gray')\n","    ax.set_title(title, fontsize=10)\n","    ax.axis('off')\n","\n","plt.tight_layout()\n","plt.show()\n"],"metadata":{"id":"u0kFBB-BCnS8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["2-3. 정확도 변화 그래프"],"metadata":{"id":"Yt6i-p42rfRC"}},{"cell_type":"code","source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","# 각 epsilons에 대해 평가\n","epsilons = [0.0, 0.05, 0.1, 0.2, 0.3]\n","results = []\n","\n","for eps in epsilons:\n","    if eps == 0:\n","        loss, acc = model.evaluate(x_test, y_test, verbose=0)\n","        print(f\"Clean test accuracy: {acc*100:.2f}%\\n\")\n","        adv_a = acc\n","        results.append({\"epsilon\": eps, \"clean_acc\": acc, \"adv_acc\": adv_a})\n","    else:\n","        print(f\"Running FGSM with epsilon={eps} ...\")\n","        clean_a, adv_a = eval_fgsm(model, x_test, y_test, epsilon=eps, batch_size=1024)\n","        print(f\"  Clean Acc: {clean_a*100:.2f}%  |  Adv Acc: {adv_a*100:.2f}%\")\n","        results.append({\"epsilon\": eps, \"clean_acc\": clean_a, \"adv_acc\": adv_a})\n","\n","# 그래프 시각화\n","df = pd.DataFrame(results)\n","plt.figure(figsize=(7,5))\n","plt.plot(df[\"epsilon\"], df[\"adv_acc\"]*100, marker='o', label=\"Accuracy\")\n","\n","plt.title(\"FGSM Attack Effect on Model Accuracy\", fontsize=14)\n","plt.xlabel(\"Epsilon (ε)\", fontsize=12)\n","plt.ylabel(\"Accuracy (%)\", fontsize=12)\n","plt.grid(True, linestyle=\"--\", alpha=0.6)\n","plt.legend()\n","plt.show()\n"],"metadata":{"id":"MYpBNmJB5uU3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["-> 적대적 교란의 크기(eps)가 증가할수록 이미지 품질은 떨어지지만 공격 성능은 향상되는 trade-off 관계를 확인할 수 있다."],"metadata":{"id":"-jr2uvga32XX"}},{"cell_type":"markdown","source":["## 3. 방어 및 비교 분석"],"metadata":{"id":"JzLrN-YyA6RM"}},{"cell_type":"markdown","source":["3-1-1. 입력 전처리 적용 (Gaussian Blurring)"],"metadata":{"id":"NxXFSuNRA9J8"}},{"cell_type":"code","source":["epsilon = 0.2\n","batch_size = 1024\n","adv_batches = []\n","\n","# 적대적 예제 생성\n","for i in range(0, len(x_test), batch_size):\n","    xb = x_test[i:i+batch_size]\n","    yb = y_test[i:i+batch_size]\n","    adv = fgsm(model, xb, yb, tf.constant(epsilon, dtype=tf.float32)).numpy()\n","    adv_batches.append(adv)\n","\n","adv_all = np.concatenate(adv_batches, axis=0)"],"metadata":{"id":"JacDBVbBNsNs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","from scipy.ndimage import gaussian_filter\n","\n","sigma_list = [0.0, 0.25, 0.5, 0.75, 1.0, 1.25, 1.5, 1.75, 2.0] # gaussian blurring 강도\n","accs_adv = []\n","accs_clean = []\n","\n","# 각 sigma별 정확도 계산\n","for s in sigma_list:\n","    # 적대적 예제에 blur 적용\n","    if s == 0:\n","        adv_blur = adv_all\n","    else:\n","        adv_blur = np.empty_like(adv_all)\n","        for i in range(len(adv_all)):\n","            adv_blur[i] = gaussian_filter(adv_all[i], sigma=s)\n","    preds_adv = np.argmax(model.predict(adv_blur, verbose=0), axis=1)\n","    acc_adv = (preds_adv == y_test).mean()\n","    accs_adv.append(acc_adv)\n","\n","    # 원본 테스트 이미지(x_test)에 blur 적용\n","    if s == 0:\n","        clean_blur = x_test\n","    else:\n","        clean_blur = np.empty_like(x_test)\n","        for i in range(len(x_test)):\n","            clean_blur[i] = gaussian_filter(x_test[i], sigma=s)\n","    preds_clean = np.argmax(model.predict(clean_blur, verbose=0), axis=1)\n","    acc_clean = (preds_clean == y_test).mean()\n","    accs_clean.append(acc_clean)\n","\n","    print(f\"σ={s:.2f} → Clean Accuracy: {acc_clean*100:.2f}%, Adv Accuracy: {acc_adv*100:.2f}%\")\n","\n","# 시각화\n","idx = np.random.randint(len(x_test))\n","clean = x_test[idx]\n","adv = adv_all[idx]\n","\n","# 기존 테스트 데이터\n","plt.figure(figsize=(18, 3))\n","for i, s in enumerate(sigma_list):\n","    plt.subplot(1, len(sigma_list), i+1)\n","    blur = gaussian_filter(clean, sigma=s)\n","    plt.imshow(blur.squeeze(), cmap='gray')\n","    plt.title(f\"Clean σ={s:.2f}\", fontsize=10)\n","    plt.axis('off')\n","plt.suptitle(\"Clean Images with Gaussian Blur\", fontsize=14)\n","plt.tight_layout()\n","plt.show()\n","\n","# 적대적 예제\n","plt.figure(figsize=(18, 3))\n","for i, s in enumerate(sigma_list):\n","    plt.subplot(1, len(sigma_list), i+1)\n","    blur = gaussian_filter(adv, sigma=s)\n","    plt.imshow(blur.squeeze(), cmap='gray')\n","    plt.title(f\"Adv σ={s:.2f}\", fontsize=10)\n","    plt.axis('off')\n","plt.suptitle(\"Adversarial Images with Gaussian Blur\", fontsize=14)\n","plt.tight_layout()\n","plt.show()\n","\n","# 정확도 변화 그래프 (Clean vs Adv)\n","plt.figure(figsize=(8,5))\n","plt.plot(sigma_list, np.array(accs_clean)*100, marker='o', linewidth=2, label='Clean + Blur')\n","plt.plot(sigma_list, np.array(accs_adv)*100, marker='s', linewidth=2, label='Adversarial + Blur')\n","plt.title(\"Accuracy vs Gaussian Blur Sigma\", fontsize=14)\n","plt.xlabel(\"Sigma (σ)\", fontsize=12)\n","plt.ylabel(\"Accuracy (%)\", fontsize=12)\n","plt.grid(True, linestyle=\"--\", alpha=0.6)\n","plt.legend()\n","plt.show()\n"],"metadata":{"id":"2StILT2Di5fa"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["-> 입력 전처리 기반의 방어 기법은 적대적 예제에 대한 방어 효과를 보이지만, 동시에 기존 모델의 일반 성능을 저하시킬 수 있다."],"metadata":{"id":"tfs1Rsug6jn1"}},{"cell_type":"markdown","source":["3-1-2. Adversarial training"],"metadata":{"id":"Dw8jpEYdUVot"}},{"cell_type":"code","source":["from tensorflow.keras.datasets import mnist\n","\n","# 데이터 불러오기\n","(x_train, y_train), (x_test, y_test) = mnist.load_data()\n","\n","# 정규화 (0~1)\n","x_train = x_train.astype(\"float32\") / 255.0\n","x_test = x_test.astype(\"float32\") / 255.0\n","\n","print(x_train.shape, y_train.shape)\n","print(x_test.shape, y_test.shape)"],"metadata":{"id":"2Fh60DFnTTS4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import tensorflow as tf\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","eps = 0.2          # FGSM 강도\n","batch_size = 1024  # 한 번에 FGSM 생성할 크기\n","num_adv_keep = 15000  # 훈련에 사용할 adversarial 샘플 개수\n","\n","# 적대적 예제 생성\n","x_adv_batches = []\n","surrogate_model = tf.keras.models.load_model(\"/content/drive/MyDrive/mnist_cnn_tf.keras\")\n","for i in range(0, len(x_train), batch_size):\n","    xb = x_train[i:i+batch_size]\n","    yb = y_train[i:i+batch_size]\n","    adv_b = fgsm(surrogate_model, xb, yb, tf.constant(eps, dtype=tf.float32)).numpy()\n","    x_adv_batches.append(adv_b)\n","\n","x_adv_full = np.concatenate(x_adv_batches, axis=0)\n","y_adv_full = y_train.copy()\n","\n","# 랜덤으로 15,000개 선택\n","rng = np.random.default_rng(42)\n","sel_idx = rng.choice(len(x_adv_full), size=num_adv_keep, replace=False)\n","x_adv = x_adv_full[sel_idx]\n","y_adv = y_adv_full[sel_idx]\n","\n","# 기존 train 데이터 + 적대적 예제 15,000개\n","x_train_new = np.concatenate([x_train, x_adv], axis=0)\n","y_train_new = np.concatenate([y_train, y_adv], axis=0)\n","\n","# 섞기\n","perm = rng.permutation(len(x_train_new))\n","x_train_new = x_train_new[perm]\n","y_train_new = y_train_new[perm]\n","\n","print(f\"기존 학습 데이터 개수: {len(x_train)}\")\n","print(f\"적대적 예제 개수: {len(x_adv)}\")\n","print(f\"최종 adversarial training에 사용된 학습 데이터 개수: {len(x_train_new)}\")"],"metadata":{"id":"1DzUJ19vsLXQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tensorflow.keras import layers, models\n","\n","# 모델 정의\n","model = models.Sequential([\n","    layers.Conv2D(32, kernel_size=(3,3), activation='relu', input_shape=(28,28,1)),\n","    layers.Conv2D(64, kernel_size=(3,3), activation='relu'),\n","    layers.MaxPooling2D(pool_size=(2,2)),\n","    layers.Dropout(0.25),\n","    layers.Flatten(),\n","    layers.Dense(128, activation='relu'),\n","    layers.Dropout(0.5),\n","    layers.Dense(10, activation='softmax')\n","])\n","\n","# 모델 컴파일\n","model.compile(\n","    optimizer='adam',\n","    loss='sparse_categorical_crossentropy',\n","    metrics=['accuracy']\n",")"],"metadata":{"id":"7V5qzsPWaUtB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# 모델 학습\n","history = model.fit(\n","    x_train_new, y_train_new,\n","    epochs=5,\n","    batch_size=64,\n","    validation_split=0.2,\n","    verbose=1\n",")\n","\n","# 학습 완료 후 모델 저장\n","save_path = \"/content/drive/MyDrive/mnist_adv.keras\"\n","model.save(save_path)"],"metadata":{"id":"QL0tpQOHaYKo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","# 정확도(Accuracy) 그래프\n","plt.figure(figsize=(7,4))\n","plt.plot(history.history['accuracy'], 'o-', label='Train Accuracy')\n","plt.plot(history.history['val_accuracy'], 's-', label='Validation Accuracy')\n","plt.title('Training and Validation Accuracy')\n","plt.xlabel('Epoch')\n","plt.ylabel('Accuracy')\n","plt.legend()\n","plt.grid(True, linestyle='--', alpha=0.6)\n","plt.show()\n","\n","# 손실(Loss) 그래프\n","plt.figure(figsize=(7,4))\n","plt.plot(history.history['loss'], 'o-', label='Train Loss')\n","plt.plot(history.history['val_loss'], 's-', label='Validation Loss')\n","plt.title('Training and Validation Loss')\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.legend()\n","plt.grid(True, linestyle='--', alpha=0.6)\n","plt.show()"],"metadata":{"id":"uR8xmm8fdhaQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import tensorflow as tf\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","eps = 0.2\n","batch_size = 1024\n","\n","# 기존 테스트 데이터에 대한 성능\n","preds_sur_clean = np.argmax(surrogate_model.predict(x_test, batch_size=batch_size, verbose=0), axis=1)\n","acc_sur_clean = (preds_sur_clean == y_test).mean()\n","\n","preds_vic_clean = np.argmax(model.predict(x_test, batch_size=batch_size, verbose=0), axis=1)\n","acc_vic_clean = (preds_vic_clean == y_test).mean()\n","\n","print(f\"Baseline 모델 - 기존 테스트 데이터 성능: {acc_sur_clean*100:.2f}%\")\n","print(f\"Adv Training 모델 - 기존 테스트 데이터 성능:    {acc_vic_clean*100:.2f}%\")\n","\n","print(f\"==============\")\n","\n","# 적대적 예제 생성\n","adv_batches = []\n","for i in range(0, len(x_test), batch_size):\n","    xb = x_test[i:i+batch_size]\n","    yb = y_test[i:i+batch_size]\n","    adv_b = fgsm(surrogate_model, xb, yb, tf.constant(eps, dtype=tf.float32)).numpy()\n","    adv_batches.append(adv_b)\n","adv_all = np.concatenate(adv_batches, axis=0)\n","\n","# 적대적 예제에 대한 성능\n","preds_sur_adv = np.argmax(surrogate_model.predict(adv_all, batch_size=batch_size, verbose=0), axis=1)\n","acc_sur_adv = (preds_sur_adv == y_test).mean()\n","\n","preds_vic_adv = np.argmax(model.predict(adv_all, batch_size=batch_size, verbose=0), axis=1)\n","acc_vic_adv = (preds_vic_adv == y_test).mean()\n","\n","print(f\"Baseline 모델 - 적대적 예제 성능: {acc_sur_adv*100:.2f}%\")\n","print(f\"Adv Training 모델 - 적대적 예제 성능: {acc_vic_adv*100:.2f}%\")\n","\n","# 시각화\n","models = ['Baseline', 'Adv Training']\n","clean_accs = [acc_sur_clean*100, acc_vic_clean*100]\n","adv_accs = [acc_sur_adv*100, acc_vic_adv*100]\n","\n","x = np.arange(len(models))\n","width = 0.35\n","\n","plt.figure(figsize=(7,5))\n","plt.bar(x - width/2, clean_accs, width, color='tab:blue', label='Clean')\n","plt.bar(x + width/2, adv_accs, width, color='tab:orange', label='Adversarial')\n","\n","plt.xticks(x, models)\n","plt.ylabel('Accuracy (%)')\n","plt.title(f'Clean vs Adversarial Accuracy (ε={eps})')\n","plt.ylim(0, 100)\n","for i, v in enumerate(clean_accs):\n","    plt.text(i, v + 1.0, f\"{v:.2f}%\", ha='center', fontsize=9, color='tab:blue')\n","for i, v in enumerate(adv_accs):\n","    plt.text(i, v - 5.0, f\"{v:.2f}%\", ha='center', fontsize=9, color='tab:orange')\n","plt.legend()\n","plt.grid(axis='y', linestyle='--', alpha=0.4)\n","plt.tight_layout()\n","plt.show()\n"],"metadata":{"id":"6jkemyP-dnJw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["| 방어 방법                    | 연산 비용 | 방어 효과 | 기존 성능 변화                       | 주요 특징                      |\n","| ------------------------ | ----- | ----- | ---------------------------------- | -------------------------- |\n","| **Gaussian Blurring**    | 낮음    | 낮음(52.27% -> 76.11%)    | 약간의 저하(99.10% -> 95.50%)                         | 구현이 단순하고 빠름 |\n","| **Adversarial Training** | 높음    | 높음(52.27% -> 99.62%)    | 미미한 저하(99.10% -> 98.93%) | 적대적 강인성이 높으나 추가 학습이 필요     |"],"metadata":{"id":"Mqp_2szp_bMM"}},{"cell_type":"markdown","source":["## 4. 확장 아이디어"],"metadata":{"id":"vFCihSOgqLxZ"}},{"cell_type":"markdown","source":["4-1. PGD 공격 구현"],"metadata":{"id":"ObCWA1hsqOiX"}},{"cell_type":"code","source":["# 적대적 공격 loss 정의\n","loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n","\n","# FGSM 공격 함수\n","def fgsm(model, images, labels, epsilon):\n","    images = tf.convert_to_tensor(images)\n","    labels = tf.convert_to_tensor(labels) # 텐서로 변환\n","    with tf.GradientTape() as tape:\n","        tape.watch(images)\n","        preds = model(images, training=False)\n","        loss = loss_object(labels, preds) # 입력값을 받았을 때 모델의 loss\n","    grad = tape.gradient(loss, images)\n","    signed_grad = tf.sign(grad) # loss가 증가하는 gradient의 방향\n","    adv = images + epsilon * signed_grad # 원본 이미지에 적대적 교란 삽입\n","    adv = tf.clip_by_value(adv, 0.0, 1.0)\n","    return adv\n","\n","def pgd(model, images, labels, epsilon, alpha, steps=10):\n","    images = tf.convert_to_tensor(images)\n","    labels = tf.convert_to_tensor(labels)\n","    adv = images + tf.random.uniform(tf.shape(images), -epsilon, epsilon) # 초반에 랜덤한 교란을 삽입\n","    adv = tf.clip_by_value(adv, 0.0, 1.0)\n","\n","    for _ in range(steps): # 반복적으로 gradient 계산 후 적대적 교란 삽입\n","        with tf.GradientTape() as tape:\n","            tape.watch(adv)\n","            preds = model(adv, training=False)\n","            loss = loss_object(labels, preds)\n","        grad = tape.gradient(loss, adv)\n","        adv = adv + alpha * tf.sign(grad)\n","        adv = tf.clip_by_value(adv, images - epsilon, images + epsilon)\n","        adv = tf.clip_by_value(adv, 0.0, 1.0)\n","    return adv"],"metadata":{"id":"KtX7DyN7jY2o"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","\n","model = tf.keras.models.load_model(\"/content/drive/MyDrive/mnist_cnn_tf.keras\")\n","\n","n_show = 2\n","eps = 0.2 # 총 적대적 교란의 크기\n","pgd_steps = 10 # PGD 반복 횟수\n","alpha = eps / pgd_steps # 한 번의 step 당 삽입하는 교란의 크기\n","\n","# 무작위 샘플 선택\n","idxs = np.random.choice(len(x_test), size=n_show, replace=False)\n","x_sel = x_test[idxs]\n","y_sel = y_test[idxs]\n","\n","# FGSM / PGD 생성\n","x_fgsm = fgsm(model, x_sel, y_sel, eps).numpy()\n","x_pgd = pgd(model, x_sel, y_sel, eps, alpha, steps=pgd_steps).numpy()\n","\n","# 모델 예측\n","p_clean = np.argmax(model.predict(x_sel, verbose=0), axis=1)\n","p_fgsm = np.argmax(model.predict(x_fgsm, verbose=0), axis=1)\n","p_pgd = np.argmax(model.predict(x_pgd, verbose=0), axis=1)\n","\n","# 시각화\n","plt.figure(figsize=(10, n_show * 2.8))\n","\n","for i in range(n_show):\n","    # Clean\n","    plt.subplot(n_show, 3, 3*i + 1)\n","    plt.imshow(x_sel[i].squeeze(), cmap='gray')\n","    color = \"blue\" if p_clean[i] == y_sel[i] else \"red\"\n","    plt.title(f\"Clean\\nTrue:{y_sel[i]} Pred:{p_clean[i]}\", color=color, fontsize=11)\n","    plt.axis('off')\n","\n","    # FGSM\n","    plt.subplot(n_show, 3, 3*i + 2)\n","    plt.imshow(x_fgsm[i].squeeze(), cmap='gray')\n","    color = \"blue\" if p_fgsm[i] == y_sel[i] else \"red\"\n","    plt.title(f\"FGSM\\nPred:{p_fgsm[i]}\", color=color, fontsize=11)\n","    plt.axis('off')\n","\n","    # PGD\n","    plt.subplot(n_show, 3, 3*i + 3)\n","    plt.imshow(x_pgd[i].squeeze(), cmap='gray')\n","    color = \"blue\" if p_pgd[i] == y_sel[i] else \"red\"\n","    plt.title(f\"PGD\\nPred:{p_pgd[i]}\", color=color, fontsize=11)\n","    plt.axis('off')\n","\n","plt.suptitle(\"Clean vs FGSM vs PGD (MNIST Adversarial Examples)\", fontsize=15, y=1.02)\n","plt.tight_layout(pad=2)\n","plt.show()\n"],"metadata":{"id":"ASZKogZhrML-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import numpy as np\n","import tensorflow as tf\n","import time\n","\n","eps = 0.2\n","pgd_steps = 10\n","alpha = eps / pgd_steps\n","batch_size = 1024\n","\n","# 적대적 예제 생성\n","# FGSM\n","x_fgsm = []\n","x_pgd = []\n","for i in range(0, len(x_test), batch_size):\n","    xb = x_test[i:i+batch_size]\n","    yb = y_test[i:i+batch_size]\n","    t0 = time.perf_counter()\n","    x_fgsm.append(fgsm(model, xb, yb, eps).numpy())\n","x_fgsm = np.concatenate(x_fgsm, axis=0)\n","t1 = time.perf_counter()\n","print(f\"FGSM generation time: {t1 - t0:.2f} s\")\n","\n","# PGD\n","for i in range(0, len(x_test), batch_size):\n","    xb = x_test[i:i+batch_size]\n","    yb = y_test[i:i+batch_size]\n","    t0 = time.perf_counter()\n","    x_pgd.append(pgd(model, xb, yb, eps, alpha, steps=pgd_steps).numpy())\n","x_pgd = np.concatenate(x_pgd, axis=0)\n","t1 = time.perf_counter()\n","print(f\"PGD generation time: {t1 - t0:.2f} s\")\n","\n","print(f\"====================================\")\n","\n","# 모델 평가\n","clean_acc = model.evaluate(x_test, y_test, verbose=0)[1]\n","fgsm_acc  = model.evaluate(x_fgsm, y_test, verbose=0)[1]\n","pgd_acc   = model.evaluate(x_pgd, y_test, verbose=0)[1]\n","\n","print(f\"Clean Accuracy: {clean_acc*100:.2f}%\")\n","print(f\"FGSM  Accuracy: {fgsm_acc*100:.2f}%\")\n","print(f\"PGD   Accuracy: {pgd_acc*100:.2f}%\")\n","\n","\n","# 시각화\n","accs = np.array([clean_acc, fgsm_acc, pgd_acc]) * 100\n","labels = ['Clean', f'FGSM (ε={eps})', f'PGD (ε={eps})']\n","\n","plt.figure(figsize=(6,5))\n","bars = plt.bar(labels, accs, color=['tab:blue','tab:orange','tab:red'])\n","plt.title(\"Model Accuracy under Different Attacks\", fontsize=14)\n","plt.ylabel(\"Accuracy (%)\")\n","plt.ylim(0, 100)\n","plt.grid(axis='y', linestyle='--', alpha=0.4)\n","\n","for bar, acc in zip(bars, accs):\n","    plt.text(bar.get_x() + bar.get_width()/2, acc + 1, f\"{acc:.2f}%\",\n","             ha='center', va='bottom', fontsize=11)\n","\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"ihzblqW_sSWF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["| 공격 방법 | 연산 비용 | 공격 효과 | 주요 특징 |\n","|------------|------------|------------|------------|\n","| **FGSM** | 낮음 | 낮음 | 한 번의 그래디언트 계산으로 교란 생성, 속도가 매우 빠름 |\n","| **PGD** | 높음 | 높음 | 여러 번 반복하여 교란 삽입, 랜덤 시작(Random Start) 사용 |\n"],"metadata":{"id":"oCuffHDlvRqV"}},{"cell_type":"code","source":[],"metadata":{"id":"yM3pFT2Ws8eG"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[{"file_id":"/v2/external/notebooks/intro.ipynb","timestamp":1762395060953}],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}